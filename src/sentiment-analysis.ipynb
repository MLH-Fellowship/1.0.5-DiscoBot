{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import torchtext.experimental\n",
    "import torchtext.experimental.vectors\n",
    "\n",
    "import collections\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifier import *\n",
    "from helpers import ep_time, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "max_len = 500\n",
    "max_size = 25000\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:09<00:00, 9.11MB/s]\n"
     ]
    }
   ],
   "source": [
    "raw_train, raw_test = torchtext.experimental.datasets.raw.IMDB()\n",
    "raw_train, raw_valid = get_train_valid_split(raw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(max_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = gen_vocab(raw_train, tokenizer, max_size=max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = process_raw(raw_train,tokenizer, vocab)\n",
    "test_data = process_raw(raw_test,tokenizer, vocab)\n",
    "valid_data = process_raw(raw_valid,tokenizer, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "pad_token = '<pad>'\n",
    "unk_token = '<unk>'\n",
    "pad_idx = vocab[pad_token]\n",
    "input_dim = len(vocab)\n",
    "emb_dim = 100\n",
    "hid_dim = 256\n",
    "output_dim = 2\n",
    "n_layers = 2\n",
    "dropout = 0.5\n",
    "n_epochs = 10\n",
    "best_valid_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = Collator(pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True, collate_fn=collator.collate)\n",
    "\n",
    "valid_iterator = torch.utils.data.DataLoader(valid_data, batch_size, shuffle=False, collate_fn=collator.collate)\n",
    "\n",
    "test_iterator = torch.utils.data.DataLoader(test_data, batch_size, shuffle=False, collate_fn=collator.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "glove.6B.zip: 100%|██████████| 862M/862M [08:18<00:00, 1.73MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
       "  (lstm): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiLSTM(input_dim, emb_dim, hid_dim, output_dim, n_layers, dropout, pad_idx)\n",
    "\n",
    "glove = torchtext.experimental.vectors.GloVe(name = '6B',\n",
    "                                             dim = emb_dim)\n",
    "# for n,p in model.named_parameters():\n",
    "#     print(f'name:{n}\\nshape:{p.shape}\\n')\n",
    "model.apply(init_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embedding, unk_tokens = get_pretrained_embedding(model.embedding, glove, vocab, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0398,  0.0357, -0.0046,  ..., -0.0485, -0.0088,  0.0329],\n",
       "        [-0.0330,  0.0428,  0.0304,  ...,  0.0236,  0.0487,  0.0101],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [-0.2925,  0.1087,  0.7920,  ..., -0.3641,  0.1822, -0.4104],\n",
       "        [-0.7250,  0.7545,  0.1637,  ..., -0.0144, -0.1761,  0.3418],\n",
       "        [ 1.1753,  0.0460, -0.3542,  ...,  0.4510,  0.0485, -0.4015]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight.data[pad_idx] = torch.zeros(emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 47s\n",
      "\tTrain Loss: 0.788 | Train Acc: 50.93%\n",
      "\t Val. Loss: 0.659 |  Val. Acc: 63.48%\n",
      "Epoch: 02 | Epoch Time: 0m 48s\n",
      "\tTrain Loss: 0.678 | Train Acc: 58.33%\n",
      "\t Val. Loss: 0.662 |  Val. Acc: 60.19%\n",
      "Epoch: 03 | Epoch Time: 0m 49s\n",
      "\tTrain Loss: 0.633 | Train Acc: 64.07%\n",
      "\t Val. Loss: 0.533 |  Val. Acc: 73.59%\n",
      "Epoch: 04 | Epoch Time: 0m 49s\n",
      "\tTrain Loss: 0.481 | Train Acc: 77.48%\n",
      "\t Val. Loss: 0.539 |  Val. Acc: 81.34%\n",
      "Epoch: 05 | Epoch Time: 0m 50s\n",
      "\tTrain Loss: 0.356 | Train Acc: 85.18%\n",
      "\t Val. Loss: 0.362 |  Val. Acc: 83.42%\n",
      "Epoch: 06 | Epoch Time: 0m 49s\n",
      "\tTrain Loss: 0.284 | Train Acc: 88.68%\n",
      "\t Val. Loss: 0.275 |  Val. Acc: 89.03%\n",
      "Epoch: 07 | Epoch Time: 0m 49s\n",
      "\tTrain Loss: 0.252 | Train Acc: 90.10%\n",
      "\t Val. Loss: 0.270 |  Val. Acc: 89.64%\n",
      "Epoch: 08 | Epoch Time: 0m 49s\n",
      "\tTrain Loss: 0.211 | Train Acc: 91.93%\n",
      "\t Val. Loss: 0.274 |  Val. Acc: 89.33%\n",
      "Epoch: 09 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.182 | Train Acc: 93.41%\n",
      "\t Val. Loss: 0.283 |  Val. Acc: 90.11%\n",
      "Epoch: 10 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.163 | Train Acc: 93.84%\n",
      "\t Val. Loss: 0.308 |  Val. Acc: 89.97%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "    \n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = ep_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'bilstm.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.291 | Test Acc: 88.15%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('bilstm.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4891465902328491"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'I fucking hate you'\n",
    "predict(tokenizer, vocab, model, device, sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
